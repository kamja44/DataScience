분류

- 몇 가지 선택사항(붓꽃의 품종) 중 하나를 선택
  클래스
- 출력될 수 있는 값(붓꽃의 종류)들
  레이블
- 데이터 포인트 하나(붓꽃 하나)에 대한 기대 출력
  - 즉, 꽃의 품종

iris 데이터 적재

- iris 데이터는 scikit-learn의 datasets 모듈에 포함되어 있다.

```py
from sklearn.datasets import load_iris
iris_dataset = load_iris()
# load_iris가 반환한 iris 객체는 키와 값 쌍으로 구성되어 있다.
print(iris_dataset.keys())

# DESCR 키에는 데이터셋에 대한 설명이 들어있다.
print(iris_dataset["DESCR"])

# target_names 키에는 예측하려는 붓꽃 품종의 이름을 문자열 배열로 가지고 있다.
print(iris_dataset["target_names"])

# feature_names의 ㄱ밧은 각 특성을 설명하는 문자열 리스트이다.
print(iris_dataset["feature_names"])

# 실제 데이터는 taret과 data 필드에 있다.
# data필드는 꽃잎의 길이와 폭, 꽃받침의 길이와 폭을 수치 값으로 가지고 있는 Numpy 배열이다.
print(type(iris_dataset["data"]))
print(iris_dataset["data"].shape) # (150,4)

# target 배열도 샘플 붓꽃의 품종을 담은 Numpy 배열이다.
print(type(iris_dataset["target"]))

# target은 각 원소가 붓꽃 하나에 해당하는 1차원 배열이다.
print(iris_dataset["target"],shape) # (150, )

# 붓꽃의 종류는 0에서 2까지의 정수로 기록되어 있으며 0은 setosa, 1은 versicolor, 2는 virginica이다.
# 숫자의 의미는 iris_dataset["target_names"]배열에서 확인할 수 있다.
print(iris_dataset["target"])
```

머신러닝에서 `각 아이템을 샘플`이라고 하고 `속성은 특성`이라고 한다.

- 즉, data배열의 크기는 샘플의 수에 특성의 수를 곱한 값이 된다.
  - 사이킷 런은 항상 데이터가 Numpy 배열 구조일 거라고 가정한다.

# 성과 측정

- 훈련 데이터와 테스트 데이터

모델을 만들 때 쓴 데이터는 평가 목적으로사용할 수 없다.
데이터를 기억한다는 것은 모델을 잘 일반화하지 않았다는 뜻이다.

- 즉, 새로운 데이터에 대해서는 잘 작동하지 않는다는 것이다.
  모델의 성능을 측정하기 위해선 새로운 데이터(이전에 본 적 없는) 데이터를 모델에 적용해야한다.
- 이를 위해 가지고 있는 데이터(150개의 붓꽃 데이터)를 두 그룹으로 나눈다.
  - 그 중 하나는 머신러닝 모델을 만들 때 사용하며, 훈련 데이터 혹은 훈련 세트(training set)라고 한다.
  - 나머지는 모델이 얼마나 잘 작동하는지 측정하는 데 사용하며, 이를 테스트 데이터, 테스트 세트(test set) 혹은 홀드아웃 세트(hold-out set)라고 한다.
    - 이를 위해 sicket-learn에서 데이터셋을 섞어서 나눠주는 `train_test_split` 함수를 제공한다.
      - 전체 데이터 중 75%를 레이블 데이터와 함께 훈련 세트로 뽑는다.
      - 나머지 25% 데이터는 레이블 데이터와 함께 테스트 세트가 된다.
      - 훈련 세트와 테스트 세트를 나누는 비율은 매개변수이므로 변경할 수 있다.

scikit-learn에서 데이터는 대문자 X로 표시하고, 레이블은 소문자 y로 표시한다.

- 이는 수학에서 함수의 입력을 x, 출력을 y로 나타내는 표준 공식에서 유래된 것이다.
  - f(x) = y

`train_test_split()`

- 전체 데이터 중 75%를 레이블 데이터와 함께 훈련 세트로 뽑는다.
- train_test_split 함수로 데이터를 나누기 전, 유사 난수 생성기를 사용하여 데이터셋을 무작위로 섞어야 한다.
  - 데이터 포인트가 레이블 순서대로 정렬되어 있기 때문이다.
    - iris_dataset["target"]의 출력을 확인해보면 데이터가 정렬되어 있다.
      - 세 클래스 중 하나만 포함된 테스트 세트를 사용하면 모델이 얼마나 잘 일반화되었는지 알 수 없다.
        - 즉, 테스트 세트가 세 클래스의 데이터를 모두 포함하도록 섞어야 한다.
- train_test_split()함수의 random_state 매개변수를 이용하여 결과가 똑같이 나오도록 유사 난수 생성기에 넣을 난수 초깃값을 random_state 매개변수로 전달할 수 있다.
- train_test_split 함수에서 test_size 매개변수로 테스트 세트의 비율을 지정할 수 있다.

`산점도`

- 데이터에서 한 특성을 x축에 놓고 다른 하나는 y축에 놓아 각 데이터 포인트를 하나의 점으로 나타내는 그래프이다.

`산점도 행렬`

- 모든 특성을 짝지어서 만든다.
  - 컴퓨터 화면이 2차원이기에 3개 이상의 특성을 표현할 때 사용
- pandas는 산점도 행렬을 그래주는 `scatter_matrix` 함수를 제공한다.
  - scatter_matrix 함수의 대각선에 위치한 그래프는 각 특성의 히스토그램이다.

`k-최근접 이웃 알고리즘(분류기)`

- 단순히 훈련 데이터를 저장하여 만들어진다.
  새로운 데이터 포인트에 대한 예측이 필요하다면 알고리즘은 새 데이터 포인트에서 가장 가까운 훈련 데이터 포인트를 찾은 후, 훈련 데이터의 레이블을 새 데이터 포인트의 레이블로 지정한다.
- k-최근접 이웃 알고리즘은 훈련 데이터에서 새로운 데이터 포인트에 가장 가까운 'k개'의 이웃을 찾는다는 의미이다.
  - 즉, 클래스 중 빈도가 가장 높은 클래스를 예측값으로 사용한다.
- k-최근접 이웃 분류 알고리즘은 neighbors 모듈 아래 KNeighborsClassifier 클래스에 구현되어있다.
  - 모델을 사용하려면 클래스로부터 객체를 생성해야 한다.
  - 이때 모델에 필요한 매개변수를 할당해야 한다.
    - k-최근접 이웃 알골지므에서 가장 중요한 매개변수는 이웃의 개수이다.

`k-최근접 이웃 알고리즘 모델 생성`

```py
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)
```

- knn 객체는 훈련 데이터로 모델을 만들고, 새로운 데이터 포인트에 대해 예측하는 알고리즘을 캡슐화 한 것이다. 또한 알고리즘이 훈련 데이터로부터 추출한 정보를 담고있다.
- KNeighborsClassifier의 경우 훈련 데이터 자체를 저장하고 있다.

훈련 데이터 셋으로부터 모델을 만드려면 knn 객체의 fit 메서드를 사용한다.

- 이 메서드는 훈련 데이터는 Numpy 배열 X_train과 훈련 데이터의 레이블을 담고 있는 NumPy 배열 y_train을 매개변수로 받는다.

```py
knn.fit(X_train, y_train)
```

- fit 메서드는 knn 객체 자체를 반환한다.
  - 그리고 knn 객체 자체를 변경시킨다.
    - 즉, knn 객체가 문자열 형태로 출력된다.

`k-최근접 이웃 알고리즘 모델 예측`

꽃받침의 길이가 5cm, 폭이 2.9cm, 꽃잎의 길이가 1cm, 폭이 0.2cm인 붓꽃을 보았다고 가정할 때, 이 꽃의 품종은 무엇일까

- NumPy 배열 즉, 샘플의 수(1)에 특성의 수(4)를 곱한 크기의 NumPy 배열로 만든다.

```py
X_new = np.array([[5,2.9,1,0.2]])
print("X_new.shape : ", X_new.shape)
```

- 붓꽃 하나의 측정값은 2차원 NumPy 배열의 행으로 들어간다.
  `scikit-learn은 항상 데이터가 2차원 배열일 것으로 예상한다.`

예측에는 knn객체의 predict 메서드를 사용한다.

```py
prediction = knn.predict(X_new)
print("예측 : ", prediction)
print("예측한 타깃의 이름 : ", iris_dataset["target_names"][prediction])
```

- k-최근접 이웃 알고리즘 모델이 꽃을 setosa 품종을 의미하는 클래스 0으로 예측한다.

`k-최근접 이웃 알고리즘 모델 평가하기`

- 테스트 데이터 세트를 사용한다.
  - 테스트 데이터 세트는 모델을 만들 때 사용하지 않았고 테스트 세트에 있는 각 붓꽃의 품종을 정확히 알고 있다.
    - 따라서 테스트 데이터에 있는 붓꽃의 품종을 예측하고 실제 레이블(품종)과 비교할 수 있다.

얼마나 많은 붓꽃 품종이 정확히 맞았는지 `정확도`를 계산하여 모델의 성능을 평가한다.

```py
y_pred = knn.predict(X_test)
print("테스트 세트에 대한 예측값 : \n", y_pred)
print("테스트 세트의 정확도 : {:.2f}".format(np.mean(y_pred == y_test)))
print("테스트 세트의 정확도 : {:.2f}".format(knn.score(X_test, y_test)))
```

- 정확도는 0.97이다.
  - 테스트 세트에 포함된 붓꽃 중 97%의 품종을 정확히 맞췄다는 의미이다.

`총정리`
iris 데이터 세트

- 분류 문제에서는 각 품종을 `클래스`라고 한다.
- 개별 붓꽃의 품종을 `레이블`이라고 한다.
- `데이터를 담고 있으면 X`로 표기한다.
- `정확한 혹은 기대하는 출력은 y`로 표기한다.
- `훈련 세트`는 모델을 구축하기 위해 사용하며
- `테스트 세트`는 모델을 평가할 때 사용한다.
- `k-최근접 이웃 분류 알고리즘`은 새 데이터 포인트를 예측하기 위해 훈련 데이터에서 가장 가까운 이웃을 선택한다.
  - KNeighborsClassifier 클래스에 구현되어 있다.
    - n_neighbors 매개변수를 이용하여 클래스의 객체를 만든다.(참조할 이웃의 개수)
      - 생성한 객체를 fit 메서드를 호출하여 모델을 만든다.
  - 모델의 정확도를 계산하는 score 메서드로 모델을 평가한다.
    - 정확도가 97%가 나왔는데 이는 테스트 세트에 있는 샘플의 97%를 정확히 맞췄다는 의미이다.

```py
from sklearn.datasets import load_iris
iris_dataset = load_iris()
from sklearn.neighbors import KNeighborsClassifier

X_train, X_test, y_train, y_test = train_test_split(
  iris_dataset["data"], iris_dataset["target"], random_state = 0
)
knn = KNeighborsClassifier(n_neighbors = 1)
knn.fit(X_train, y_train)
print("테스트 세트의 정확도 : {:.2f}".format(knn.score(X_test, y_test)))
```

`fit, predict, score 메서드는 scikit-learn 지도 학습 모델의 공통 인터페이스이다.`
