# 지도 학습의 분류

- 분류(classification)와 회귀(regression)

분류

- 미리 정의된 가능성 있는 여러 `클래스 레이블`중 하나를 예측한다.
  - 딱 두개의 클래스로 분류하는 이진 분류
    - 이진 분류에서는 한 클래스를 양성 클래스, 다른 하나를 음성 클래스라고도 한다.
      - 양성 클래스는 학습하고자 하는 대상을 의미한다.
        - 즉, 양성 클래스라고 해서 좋은값이나 장점을 나타내는 것이 아니다.
  - 셋 이상의 클래스로 분류하는 다중 분류로 나뉜다.

회귀

- 연속적인 숫자, 또는 프로그래밍 용어로 말하면 부동소숫점을 예측하는 것이다.

`출력 값에 연속성이 있는지 확인`하면 회귀와 분류 문제를 쉽게 구분할 수 있다.

# 일반화, 과대적합, 과소적합

일반화(generalization)

- 모델이 처음 보는 데이터에 대해서 정확하게 예측할 수 있다면 이를 훈련 세트에서 테스트 세트로 일반화 되었다고 한다.
  - 모델을 만들 때는 가능한 정확하게 일반화되도록 해야 한다.
  - `지도 학습에서는 훈련 데이터로 학습한 모델이 훈련 데이터와 특성이 같다면 처음 보는 새로운 데이터가 주어져도 정확히 예측할 거라 기대한다.`
    - 하지만 모델이 일반화되면 새로운 데이터에 대한 예측이 정확하지 않다.
      - 즉, 훈련 세트에서 100% 정확도를 달성하는 것은 크게 도움되지 않는다.

과대적합(overfiting)

- 가진 정보를 모두 사용해서 너무 복잡한 모델을 만들었을 경우
- 모델이 훈련 세트의 각 샘플에 너무 가깝게 맞춰져서 새로운 데이터에 일반화되기 어려울 때 발생한다.

과소적합(underfiting)

- 너무 간단한 모델이 선택되는 경우

`모델을 복잡하게 할수록 훈련 데이터에 대해선 정확히 예측할 수있지만, 훈련 세트의 각 데이터 포인트에 너무 민감해져서 새로운 데이터에 잘 일반화되지 못한다.(새로운 데이터에 대해 제대로 된 예측을 못한다.)`

## 예제에 사용할 데이터셋

forge

- 두 개의 특성을 가진 데이터셋이다.
  - 인위적으로 만든 이진 분류 데이터이다.

forge 데이터셋 산점도로 표현

```py
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import mglearn
# 데이터셋 생성
X, y = mglearn.datasets.make_forge()
# 산점도
mglearn.discrete_scatter(X[:, 0],X[:, 1], y)
plt.legend(["클래스 0", "클래스 1"], loc=4)
plt.xlabel("첫 번째 특성")
plt.ylabel("두 번쨰 특성")
print("X.shape : ", X.shape)
```

- x 축은 첫 번째 특성이고, y 축은 두 번째 특성이다.
- 산점도는 점 하나가 각 데이터 포인트를 나타낸다.
  - 점과 색의 모양은 데이터 포인트가 속한 클래스를 나타낸다.

회귀 알고리즘 설명에는 인위적으로 만든 wave 데이터셋을 사용한다.

- wave 데이터셋은 입력 특성 하나와 모델링할 타깃 변수(응답)를 가진다.

```py
X,y = mglearn.datasets.make_wave(n_samples=40)
plt.plot(X,y,"o")
plt.ylim(-3,3)
plt.xlabel("특성")
plt.ylabel("타깃")
```

- 특성을 x축에 놓고 회귀의 타깃(출력)을 y축에 놓는다.

# 실제 데이터셋은 위스콘신 유방암 데이터셋과 보스턴 주택가격 데이터셋을 사용한다.

위스콘신 유방암 데이터셋

- 각 종양은 양성과 악성으로 레이블되어 있다.
  - 조직 데이터를 기반으로 종양이 악성인지를 예측할 수 있도록 학습해야한다.
- 596개의 데이터 포인트를 가지고 있고 특성은 30개이다.
  - 596개의 데이터 포인트 중 212개는 악성이고 357개는 양성이다.
- feature_names 속성을 확인하면 각 특성의 의미를 알 수 있다.
- 데이터에 관한 더 자세한 정보는 cancer.DESCR에서 확인할 수 있다.

```py
# 위스콘신 유방암 데이터셋
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()
print("cancer.keys():\n", cancer.keys())
print("유방암 데이터의 형태 : ", cancer.data.shape) # 유방암 데이터의 형태 : (569, 30)
print("클래스별 샘플 개수: \n",
{n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))})
# 클래스별 샘플 개수: {'malignant': 212, 'benign': 357}
print("특성 이름 : \n", cancer.feature_names)
```

- scikit-learn에 포함된 데이터셋은 실제 데이터와 데이터셋 관련 정보를 담고 있는 Bunch 객체에 저장되어 있다.
  - Bunch 객체는 파이썬의 딕셔너리와 비슷하지만 점 표기법을 사용할 수 있다.
    - 즉, bunch["key"] 대신 bunch.key로 사용할 수 있다.

회귀 분석용 실제 데이터셋으로 사용할 보스턴 주택가격 데이터셋

- 범죄율, 찰스강 인접도, 고속도로 접근성 등의 정보를 이용하여 1970년대 보스턴 주변의 주택 평균 가격을 예측하는게 목표인 데이터셋이다.
- 506개의 데이터 포인트와 13개의 특성이 있다.
  - 이 데이터셋에서는 13개의 입력 특성뿐 아니라 특성끼리 곱하여 특성을 의도적으로 확장한다.
    - 즉, 범죄율과 고속도로 접근성의 개별 특성은 물론, 범죄율과 고속도로 접근성의 곱도 특성으로 생각한다.
      - 이와 같이 특성을 유도해내는 것을 `특성 공학`이라고 한다.
        - 유도된 데이터 셋은 load_extended_boston 함수를 사용하여 불러들일 수 있다.
        - 13개의 원래 특성에 13개에서 2개씩(중복 포함) 짝지은 91개의 특성을 더해 총 104개의 특성이 된다.
          - 13+12+11+10+9+8+...+1 = 91

```py
from sklearn.datasets import load_boston
boston = load_boston()
print("데이터의 형태 : ", boston.data.shape) # 데이터의 형태 :  (506, 13)
# 특성 공학 적용
X,y = mglearn.datasets.load_extended_boston()
print("X.shape : ", X.shape) # X.shape :  (506, 104)
```
